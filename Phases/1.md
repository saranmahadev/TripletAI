## Phase 1: MVP Breakdown

**Timeline:** April 6 - May 4, 2025  
**Goal:** Deliver a fully functional, open-source VS Code extension with essential AI features.

---

### Week 1: Inline Code Completion (April 6 - April 12)
**Objective:** Set up an AI model and implement inline code completion for JavaScript (JS), Python, and TypeScript (TS).

- **Task 1:** Identify requirements for the AI model (e.g., lightweight, code completion capability).
- **Task 2:** Research available models on Ollama (e.g., Llama 3 7B, CodeLlama).
- **Task 3:** Compare model performance based on size, speed, and accuracy for code tasks.
- **Task 4:** Select a model (e.g., Llama 3 7B) and document the choice with reasoning.
- **Task 5:** Install Ollama on the development machine (e.g., via Homebrew or direct download).
- **Task 6:** Pull the selected AI model using `ollama pull <model-name>`.
- **Task 7:** Start the Ollama server with `ollama serve`.
- **Task 8:** Send a test query to the model via `curl` (e.g., "Complete this: `function add(a, b)`").
- **Task 9:** Verify the model responds correctly and log the output.
- **Task 10:** Set up a basic VS Code extension project using `yo code`.
- **Task 11:** Install `axios` in the extension project for API calls (`npm install axios`).
- **Task 12:** Write a function to query the Ollama API (e.g., `queryOllama(prompt)`).
- **Task 13:** Test the function by logging a sample response in the extension console.
- **Task 14:** Handle API errors (e.g., connection refused) with basic error logging.
- **Task 15:** Access the active text editor using `vscode.window.activeTextEditor`.
- **Task 16:** Capture the current line of code up to the cursor position.
- **Task 17:** Extract 5 lines of context before the cursor for better suggestions.
- **Task 18:** Combine context and current line into a prompt string.
- **Task 19:** Send the prompt to the AI model and log the response.
- **Task 20:** Register a completion provider with `vscode.languages.registerCompletionItemProvider`.
- **Task 21:** Define trigger characters (e.g., `.`, `Tab`) for suggestions.
- **Task 22:** Parse the AI model’s response into a single-line suggestion.
- **Task 23:** Create a `CompletionItem` with the suggestion text.
- **Task 24:** Test the provider by typing in a JS file and verifying suggestions appear.
- **Task 25:** Create a test JS file with sample code (e.g., `function add(a, b)`).
- **Task 26:** Trigger the completion provider at various points (e.g., after `function`, `.`).
- **Task 27:** Verify suggestions are contextually relevant (e.g., `return a + b`).
- **Task 28:** Log any failures or irrelevant suggestions for debugging.
- **Task 29:** Fix minor issues (e.g., suggestion formatting) based on test results.
- **Task 30:** Create a test Python file (e.g., `def add(a, b):`).
- **Task 31:** Trigger completion and verify Python-specific suggestions (e.g., `return a + b`).
- **Task 32:** Create a test TS file (e.g., `function add(a: number, b: number)`).
- **Task 33:** Trigger completion and verify TS-specific suggestions.
- **Task 34:** Document any language-specific issues for Week 4 fixes.

**Deliverable:** Inline code completion working for JS, Python, and TS with a local AI model.

---

### Week 2: Basic Chat Interface (April 13 - April 19)
**Objective:** Build a chat interface for users to interact with the AI model.

- **Task 1:** Create a command to open the chat panel (e.g., `tripletAI.openChat`).
- **Task 2:** Initialize a Webview panel using `vscode.window.createWebviewPanel`.
- **Task 3:** Write basic HTML for the chat UI (input field, send button, response area).
- **Task 4:** Add minimal CSS for layout (e.g., flexbox for input and responses).
- **Task 5:** Test opening the Webview and verify the UI renders correctly.
- **Task 6:** Add a message listener in the Webview to capture user input.
- **Task 7:** Send the input to the extension via `webview.postMessage`.
- **Task 8:** Extract selected code from the active editor as context.
- **Task 9:** Combine user query and code context into a prompt.
- **Task 10:** Query the AI model with the prompt and log the response.
- **Task 11:** Send the AI response back to the Webview via `webview.postMessage`.
- **Task 12:** Write JavaScript in the Webview to append responses to the UI.
- **Task 13:** Format the response as plain text with basic styling.
- **Task 14:** Test sending a query (e.g., “Explain this code”) and verify the response displays.
- **Task 15:** Clear the input field after sending a query.
- **Task 16:** Add error handling for no Ollama server running (display “Server offline”).
- **Task 17:** Handle empty queries by showing a prompt (e.g., “Type a question”).
- **Task 18:** Manage long responses by truncating or scrolling the response area.
- **Task 19:** Test error cases (e.g., no internet, invalid input) and verify fallback messages.
- **Task 20:** Log errors in the extension console for debugging.
- **Task 21:** Test a code explanation query with selected JS code.
- **Task 22:** Test a code generation query (e.g., “Write a loop in Python”).
- **Task 23:** Test a general query (e.g., “What is a closure?”).
- **Task 24:** Verify responses are accurate and context-aware.
- **Task 25:** Note any inconsistencies for refinement.
- **Task 26:** Adjust UI spacing and font size for readability.
- **Task 27:** Add a loading indicator while waiting for AI responses.
- **Task 28:** Enable Enter key to send queries (not just button click).
- **Task 29:** Retest the chat with refined UI and verify improvements.
- **Task 30:** Finalize the chat design for user-friendliness.
- **Task 31:** Write a README section on using the chat feature.
- **Task 32:** Add an in-extension help command linking to the README.
- **Task 33:** Include example queries (e.g., “Explain this code”).
- **Task 34:** Proofread documentation for clarity.
- **Task 35:** Commit documentation changes to the repository.

**Deliverable:** A functional chat interface for AI interaction with context support.

---

### Week 3: Local AI Integration and Configuration (April 20 - April 26)
**Objective:** Integrate a local AI model and add user-configurable settings.

- **Task 1:** Reconfirm the chosen model (e.g., Llama 3 7B) is lightweight enough.
- **Task 2:** Test model performance on a mid-range machine (e.g., 8GB RAM).
- **Task 3:** Document system requirements for running the model locally.
- **Task 4:** Finalize the model choice for local integration.
- **Task 5:** Update project notes with the decision.
- **Task 6:** Verify Ollama is installed and running.
- **Task 7:** Ensure the model is downloaded and accessible via `ollama list`.
- **Task 8:** Test the model with a code completion query locally.
- **Task 9:** Test the model with a chat query locally.
- **Task 10:** Log setup time and performance metrics.
- **Task 11:** Update the `queryOllama` function to use the local endpoint by default.
- **Task 12:** Test code completion using the local model.
- **Task 13:** Test chat queries using the local model.
- **Task 14:** Verify response times are acceptable (<2 seconds).
- **Task 15:** Handle cases where the local model is unavailable.
- **Task 16:** Define a setting for model type (local vs. cloud) in `package.json`.
- **Task 17:** Add an API key field for cloud models in `package.json`.
- **Task 18:** Read settings using `vscode.workspace.getConfiguration`.
- **Task 19:** Update `queryOllama` to respect the model type setting.
- **Task 20:** Test switching between local and a dummy cloud endpoint.
- **Task 21:** Add a suggestion length setting (e.g., max characters) in `package.json`.
- **Task 22:** Create a command to open the settings UI (`tripletAI.configure`).
- **Task 23:** Use `vscode.workspace.openTextDocument` to show settings.json.
- **Task 24:** Test changing settings and verify they apply in the extension.
- **Task 25:** Add tooltips or comments in `package.json` for each setting.
- **Task 26:** Test code completion with local model enabled.
- **Task 27:** Test chat with local model enabled.
- **Task 28:** Switch to cloud mode (simulated) and test both features.
- **Task 29:** Change suggestion length and verify it affects completions.
- **Task 30:** Fix any bugs found during testing.
- **Task 31:** Write README instructions for installing Ollama.
- **Task 32:** Add steps to download and run the local model.
- **Task 33:** Document configuration options (model type, API key, suggestion length).
- **Task 34:** Include troubleshooting tips (e.g., “Ollama not running”).
- **Task 35:** Commit and push documentation updates.

**Deliverable:** Local AI integration with user-configurable settings.

---

### Week 4: Language Support and Final Testing (April 27 - May 4)
**Objective:** Enhance language support and prepare the extension for release.

- **Task 1:** Install Tree-sitter for JS, Python, and TS parsing.
- **Task 2:** Parse the current file’s syntax to identify language constructs.
- **Task 3:** Tailor JS completion prompts (e.g., suggest `console.log` after `.`).
- **Task 4:** Tailor Python prompts (e.g., suggest `print()`).
- **Task 5:** Tailor TS prompts (e.g., suggest type annotations).
- **Task 6:** Detect the active file’s language using `document.languageId`.
- **Task 7:** Add language context to chat prompts (e.g., “In Python: explain this”).
- **Task 8:** Test JS-specific chat queries (e.g., “What’s a Promise?”).
- **Task 9:** Test Python-specific queries (e.g., “How to use list comprehension?”).
- **Task 10:** Test TS-specific queries (e.g., “Explain interfaces”).
- **Task 11:** Test code completion in a complex JS file (e.g., with classes).
- **Task 12:** Test chat with JS-specific questions and selected code.
- **Task 13:** Verify suggestions match JS syntax and conventions.
- **Task 14:** Log any failures or delays for debugging.
- **Task 15:** Fix JS-specific issues identified.
- **Task 16:** Test code completion in a Python script (e.g., with imports).
- **Task 17:** Test chat with Python-specific questions.
- **Task 18:** Verify suggestions align with Python style (e.g., PEP 8).
- **Task 19:** Log and address any Python-specific bugs.
- **Task 20:** Retest fixed issues.
- **Task 21:** Test completion in a TS file with types and interfaces.
- **Task 22:** Test chat with TS-specific questions (e.g., “What’s a type guard?”).
- **Task 23:** Verify suggestions respect TS syntax.
- **Task 24:** Log and fix TS-specific issues.
- **Task 25:** Confirm all TS tests pass.
- **Task 26:** Test with a multi-language project (JS, Python, TS files).
- **Task 27:** Test edge cases (e.g., large files, no selection, empty files).
- **Task 28:** Verify local and cloud modes work across all features.
- **Task 29:** Fix any bugs or performance issues found.
- **Task 30:** Run a final sanity check on all features.
- **Task 31:** Update `package.json` with version `0.1.0` and metadata.
- **Task 32:** Write a changelog for v0.1 features and fixes.
- **Task 33:** Package the extension using `vsce package`.
- **Task 34:** Test installing the `.vsix` file locally.
- **Task 35:** Finalize README with installation and usage instructions.
- **Task 36:** Publish the extension to the VS Code Marketplace using `vsce publish`.
- **Task 37:** Create a GitHub Release with the `.vsix` file and changelog.
- **Task 38:** Write an announcement post for X, Reddit, and Discord.
- **Task 39:** Share the announcement with links to the Marketplace and repo.
- **Task 40:** Monitor feedback and prepare for post-release fixes.

**Deliverable:** **TripletAI v0.1** released with multi-language support and full functionality.

---
